#!/usr/bin/env python3

import os
import argparse
import pathlib
import logging
import datetime
import time
import shutil
import sys
import socket
import copy
import traceback
import json

from dask import delayed, compute, visualize
from dask.distributed import Client, LocalCluster, wait, get_worker
from dask_jobqueue import SLURMCluster
from dask.graph_manipulation import bind, checkpoint
import pandas as pd
from dask import config as cfg

from lightcurve import Exposure, Lightcurve

cfg.set({'distributed.scheduler.worker-ttl': None})

from deppol_utils import run_and_log, dump_timings, dump_timings_reduce, load_timings, quadrants_from_band_path, noprocess_quadrants


ztf_filtercodes = ['zg', 'zr', 'zi', 'all']
poloka_func = []


import deppol_misc

poloka_func.append({'map': deppol_misc.psf_study, 'reduce': deppol_misc.psf_study_reduce})
poloka_func.append({'map': deppol_misc.clean, 'reduce': deppol_misc.clean_reduce})
poloka_func.append({'reduce': deppol_misc.retrieve_catalogs})
poloka_func.append({'map': deppol_misc.match_catalogs})
poloka_func.append({'map': deppol_misc.clean, 'reduce': deppol_misc.clean_reduce})
# poloka_func.append({'map': deppol_misc.stats, 'reduce': deppol_misc.stats_reduce})
poloka_func.append({'reduce': deppol_misc.filter_seeing})
poloka_func.append({'reduce': deppol_misc.filter_psfstars_count})
poloka_func.append({'reduce': deppol_misc.filter_astro_chi2})
poloka_func.append({'map': deppol_misc.discard_calibrated, 'rm': deppol_misc.discard_calibrated_rm})
# poloka_func.append({'reduce': deppol_misc.seeing_study})
poloka_func.append({'map': deppol_misc.catalogs_to_ds9regions})
poloka_func.append({'reduce': deppol_misc.compress_lightcurve})


import deppol_psfstudy
poloka_func.append({'reduce': deppol_psfstudy.psfstudy})


import deppol_preprocess
poloka_func.append({'map': deppol_preprocess.make_catalog, 'rm': deppol_preprocess.make_catalog_rm})
poloka_func.append({'map': deppol_preprocess.mkcat2, 'rm': deppol_preprocess.mkcat2_rm})
poloka_func.append({'map': deppol_preprocess.makepsf, 'rm': deppol_preprocess.makepsf_rm})
poloka_func.append({'map': deppol_preprocess.preprocess, 'rm': deppol_preprocess.preprocess_rm})


import deppol_smphot
poloka_func.append({'reduce': deppol_smphot.reference_quadrant})
poloka_func.append({'reduce': deppol_smphot.smphot})
poloka_func.append({'reduce': deppol_smphot.smphot_plot})
poloka_func.append({'reduce': deppol_smphot.smphot_stars})
poloka_func.append({'reduce': deppol_smphot.smphot_stars_plot})


import deppol_astrometry

poloka_func.append({'reduce': deppol_astrometry.wcs_residuals})
poloka_func.append({'reduce': deppol_astrometry.astrometry_fit})
poloka_func.append({'reduce': deppol_astrometry.astrometry_fit_plot})


import deppol_photometry

poloka_func.append({'reduce': deppol_photometry.photometry_fit})
poloka_func.append({'reduce': deppol_photometry.photometry_fit_plot})


poloka_func = dict(zip([list(func.values())[0].__name__ for func in poloka_func], poloka_func))


def dump_node_config(args):
    logger = logging.getLogger("dump")
    logger.addHandler(logging.StreamHandler())
    logger.setLevel(logging.INFO)

    run_and_log(["lscpu"], logger)

    run_and_log(["df", "-h"], logger)

    if args.scratch:
        if args.scratch.exists():
            scratch_usage = shutil.disk_usage(args.scratch)
            print("Scratch disk usage")
            print("  Total: {:.2f} GB".format(scratch_usage.total/1e9))
            print("  Used : {:.2f} GB".format(scratch_usage.used/1e9))
            print("  Free : {:.2f} GB".format(scratch_usage.free/1e9))

        if 'TMPDIR' in os.environ:
            run_and_log(["ls", "-lah", os.environ['TMPDIR']], logger)


def map_op(exposure_name, wd, name, filtercode, func, args):
    try:
        exposure = Exposure(Lightcurve(ztfname, filtercode, wd), exposure_name)

        start_time = time.perf_counter()
        exposure_path = wd.joinpath("{}/{}/{}".format(name, filtercode, exposure_name))
        lightcurve_path = wd.joinpath("{}/{}".format(name, filtercode))

        logger = None
        if func != 'clean':
            if exposure_name in exposure.lightcurve.get_noprocess():
                return

            logger = logging.getLogger(exposure_name)
            logger.setLevel(logging.INFO)

            if args.exposure_workspace:
                # If exposure working directory is specified (such as using /dev/shm), rebuild the exposure object accordingly
                exposure_workspace = args.exposure_workspace.joinpath(exposure_name)
                shutil.copytree(exposure_path, exposure_workspace, symlinks=False, dirs_exist_ok=True)
                exposure_path = exposure_workspace
                exposure = Exposure(Lightcurve(name, filtercode, wd), exposure_name, path=exposure_path)

            # logger_mode = 'a'
            # if args.log_overwrite and (func == args.func.split(",")[0]):
            #     logger_mode = 'w'

            #logger.addHandler(logging.FileHandler(str(exposure_path.joinpath("output.log")), mode=logger_mode))
            logger.addHandler(logging.FileHandler(str(exposure_path.joinpath("output.log")), mode='a'))
            logger.info("")
            logger.info("="*80)
            logger.info("{}-{}".format(ztfname, filtercode))
            logger.info(datetime.datetime.today())
            logger.info("Running map operation \"{}\" on exposure {}.".format(func, exposure_name))
            logger.info("Exposure directory: {}".format(exposure_path))
            logger.info("Working directory: {}".format(wd))

        result = False
        try:
            start_time = time.perf_counter()
            result = poloka_func[func]['map'](exposure, logger, args)
        except Exception as e:
            if func != 'clean':
                logger.error(traceback.format_exc())

            print("{}-{}: {}".format(name, filtercode, func))
            print("Exposure: {}".format(exposure_name))
            print(e)
            print(traceback.format_exc())
            result = False
        finally:
            end_time = time.perf_counter()
            if func != 'clean':
                logger.info("End of func \"{}\".".format(func))

                if result:
                    exposure_path.joinpath("{}.success".format(func)).touch()
                else:
                    exposure_path.joinpath("{}.fail".format(func)).touch()

                # Remove intermediate files if any
                if args.rm_intermediates and 'rm' in poloka_func[func].keys():
                    logger.info("Removing intermediate files...")
                    for f in poloka_func[func]['rm']:
                        to_remove = exposure_path.joinpath(f)
                        if to_remove.exists():
                            to_remove.unlink()
                        else:
                            logger.warning("Tried to remove {} but it does not exist!".format(f))
                            logger.warning(" Full path: {}".format(to_remove))

                if args.dump_timings:
                    dump_timings(start_time, end_time, exposure_path.joinpath("timings_{}".format(func)))

                if args.exposure_workspace:
                    logger.info("Copying exposure data from temporary working directory back into original.")
                    exposure_path.joinpath("elixir.fits").unlink()
                    shutil.copytree(exposure_path, wd.joinpath("{}/{}/{}".format(name, filtercode, exposure_name)), dirs_exist_ok=True)
                    logger.info("Erasing exposure data from temporary working directory.")
                    shutil.rmtree(exposure_path)

                [handler.close() for handler in logger.handlers] # Needed to flush last msg

    except Exception as e:
        print("Exception raised for exposure {} in {}-{}!".format(exposure_name, ztfname, filtercode))
        traceback.print_exc()
        print("{} content:".format(exposure_path))
        print(list(exposure_path.glob("*")))
        return False
    else:
        return result


def reduce_op(wd, name, filtercode, func, save_stats, args):
    lightcurve_path = wd.joinpath("{}/{}".format(ztfname, filtercode))
    lightcurve = Lightcurve(name, filtercode, wd)
    # If we want to agregate run statistics on the previous map operation
    # if save_stats and results is not None and any(results) and func != 'clean':
    #     results_df = pd.DataFrame([result for result in results if result is not None], columns=['result', 'time_end', 'time_start', 'worker_id'])
    #     results_df.to_csv(folder.joinpath("results_{}.csv".format(func)), index=False)

    # if func != 'clean':
    #     pass

    start_time = time.perf_counter()
    if func != 'clean' and 'reduce' in poloka_func[func].keys():
        logger = logging.getLogger("{}-{}".format(name, filtercode))
        if not logger.handlers:
            # logger_mode = 'a'
            # if args.log_overwrite:
            #     logger_mode = 'w'

            #logger.addHandler(logging.FileHandler(band_path.joinpath("output.log"), mode=logger_mode))
            logger.addHandler(logging.FileHandler(band_path.joinpath("output.log"), mode='a'))
            logger.addHandler(logging.StreamHandler())
            logger.setLevel(logging.INFO)

        logger.info("")
        logger.info("="*80)
        logger.info("{}-{}".format(ztfname, filtercode))
        logger.info(datetime.datetime.today())
        logger.info("Running reduction {}".format(func))
    else:
        logger = None

    if 'reduce' in poloka_func[func].keys():
        try:
            #result = poloka_func[func]['reduce'](band_path, ztfname, filtercode, logger, args)
            result = poloka_func[func]['reduce'](lightcurve, logger, args)
        except Exception as e:
            result = False
            if func != 'clean':
                logger.error("{}-{}: {}".format(name, filtercode, func))
                logger.error(traceback.format_exc())
            else:
                print("{}-{}: {}".format(name, filtercode, func))
                traceback.print_exc()
        finally:
            end_time = time.perf_counter()
            if func != 'clean':
                logger.info("="*80)

                if result:
                    lightcurve_path.joinpath("{}.success".format(func)).touch()
                else:
                    lightcurve_path.joinpath("{}.fail".format(func)).touch()
            else:
                return 0

    if args.dump_timings and func != 'clean':
        map_start_time = None
        map_end_time = None
        if 'map' in poloka_func[func].keys():
            # quadrants = quadrants_from_band_path(band_path, None, check_files=["{}.success".format(func)])
            exposures = lightcurve.get_exposures(files_to_check="{}.success".format(func))
            timings = [load_timings(exposure.path.joinpath("timings_{}".format(func))) for exposure in exposures if exposure.joinpath("{}.success".format(func)).exists()]
            timings_df = pd.DataFrame.from_records(timings)
            timings_df['exposure'] = list(map(lambda x: x.name, exposures))
            timings_df.set_index('exposure', inplace=True)

            map_start_time = timings_df['start'].min()
            map_end_time = timings_df['end'].max()

        dump_timings_reduce({'map': map_start_time, 'reduce': start_time},
                            {'map': map_end_time, 'reduce': end_time},
                            band_path.joinpath("timings_{}".format(func)))

    return 0


if __name__ == '__main__':
    argparser = argparse.ArgumentParser(description="")
    argparser.add_argument('--ztfname', type=pathlib.Path, help="If provided, perform computation on one SN1a. If it points to a valid text file, will perform computation on all keys. If not provided, process the whole working directory.")
    argparser.add_argument('-j', '--n_proc', dest='n_jobs', type=int, default=1)
    argparser.add_argument('--wd', type=pathlib.Path, help="Working directory")
    argparser.add_argument('--filtercode', choices=ztf_filtercodes, default='all', help="Only perform computations on one or all filters.")
    argparser.add_argument('--func', type=str, help="Pipeline function to run. Several functions can be run sequencialy by separating them with commas, eg: \"make_catalog,mkcat2,makepsf\". Available functions: {}".format(list(poloka_func.keys())))
    argparser.add_argument('--no-map', dest='no_map', action='store_true', help="Skip map operations.")
    argparser.add_argument('--no-reduce', dest='no_reduce', action='store_true', help="Skip reduce operations.")
    argparser.add_argument('--cluster-worker', type=int, default=0)
    argparser.add_argument('--scratch', type=pathlib.Path, help="")
    argparser.add_argument('--from-scratch', action='store_true', help="When using scratch, does not transfer from distant directory first.")
    argparser.add_argument('--exposure-workspace', type=pathlib.Path, help="Exposure workspace directory to use instead of the one given by --wd. Useful to acceleratre IOs by moving onto a SSD disk or in memory mapped filesystem.")
    argparser.add_argument('--lc-folder', dest='lc_folder', type=pathlib.Path)
    argparser.add_argument('--astro-degree', type=int, default=3, help="Degree of ref->quadrant polynomial transformations for relative astrometric.")
    argparser.add_argument('--dump-timings', action='store_true')
    argparser.add_argument('--rm-intermediates', action='store_true', help="Remove intermediate files generated by Poloka.")
    argparser.add_argument('--synchronous-compute', action='store_true', help="Run computation synchronously on the main thread. Usefull for debugging and plotting on the fly.")
    argparser.add_argument('--astro-min-mag', type=float, default=None)
    argparser.add_argument('--log-std', action='store_true', help="If set, output log to standard output.")
    argparser.add_argument('--max-seeing', type=float, default=4.)
    argparser.add_argument('--photom-max-star-chi2', type=float, default=0.1)
    argparser.add_argument('--min-psfstars', type=int, default=None)
    argparser.add_argument('--use-raw', action='store_true', help="If set, uses raw images instead of science images.")
    argparser.add_argument('--astro-max-chi2', type=float, default=0.5)
    argparser.add_argument('--discard-calibrated', action='store_true')
    argparser.add_argument('--dump-node-info', action='store_true')
    argparser.add_argument('--log-overwrite', action='store_true', help="If set, all logs will be overwritten.")
    argparser.add_argument('--parallel-reduce', action='store_true', help="If set, parallelize reduce operations (if op has a parallel codepath).")
    argparser.add_argument('--refexp', type=str)
    argparser.add_argument('--compress', action='store_true', help="If set, work with compressed working directory")
    argparser.add_argument('--photom-cat', choices=['gaia', 'ps1', 'ubercal'], type=str, help="Star catalog to use for relative photometry.")
    argparser.add_argument('--use-gaia-stars', action='store_true', help="If set, uses Gaia to find stars (ie to build the standalone_stars.list catalog)")

    logger = logging.getLogger("main")
    #logger.addHandler(logging.StreamHandler())

    args = argparser.parse_args()
    args.wd = args.wd.expanduser().resolve()

    if args.exposure_workspace:
        args.exposure_workspace = args.exposure_workspace.expanduser().resolve()

    if args.scratch:
        args.scratch = args.scratch.expanduser().resolve()

    filtercodes = ztf_filtercodes[:3]
    if args.filtercode != 'all':
        filtercodes = [args.filtercode]

    print("Run parameters:")
    print(args)

    # Read ztfnames
    ztfnames = None
    if args.ztfname is not None:
        if args.ztfname.stem == str(args.ztfname):
            ztfnames = [str(args.ztfname)]
        else:
            args.ztfname = args.ztfname.expanduser().resolve()
            if args.ztfname.exists():
                with open(args.ztfname, 'r') as f:
                    ztfnames = [ztfname[:-1] for ztfname in f.readlines()]
            else:
                pass

    if args.dump_node_info:
        dump_node_config(args)

    print("Found {} SN1a".format(len(ztfnames)))

    # Parse pipeline function
    funcs = args.func.split(",")
    for func in funcs:
        if func not in poloka_func.keys():
            print("\"{}\" func does not exist!".format(func))
            print("Available pipeline funcs:")
            print(list(poloka_func.keys()))
            exit()

    if args.compress:
        funcs.append("compress_lightcurve")

    print("Running pipeline:")
    print(" -> ".join(funcs))

    # Temporary folder creation
    # if args.quadrant_workspace or args.scratch:
    #     import signal
    #     import atexit
    #     def delete_tree_at_exit(tree_path):
    #         shutil.rmtree(tree_path, ignore_errors=True)

    #     if args.quadrant_workspace:
    #         args.quadrant_workspace.mkdir(exist_ok=True, parents=True)
    #         atexit.register(delete_tree_at_exit, tree_path=args.quadrant_workspace)

    #     if args.scratch:
    #         args.scratch.mkdir(exist_ok=True, parents=True)
    #         atexit.register(delete_tree_at_exit, tree_path=args.scratch)

    # Allocate cluster
    if args.cluster_worker > 0:
        cluster = SLURMCluster(cores=args.n_jobs,
                               processes=args.n_jobs,
                               memory="{}GB".format(3*args.n_jobs),
                               project="ztf",
                               walltime="12:00:00",
                               queue="htc",
                               job_extra=["-L sps"])

        cluster.scale(jobs=args.cluster_worker)
        client = Client(cluster)
        print(client.dashboard_link, flush=True)
        print(socket.gethostname(), flush=True)
        print("Running {} workers with {} processes each ({} total).".format(args.cluster_worker, args.n_jobs, args.cluster_worker*args.n_jobs))
        client.wait_for_workers(1)
    elif not args.synchronous_compute:
        #localCluster = LocalCluster(n_workers=args.n_jobs, dashboard_address='localhost:8787', memory_limit="{}GB".format(3*args.n_jobs), processes=True, threads_per_worker=1)
        #localCluster = LocalCluster(n_workers=args.n_jobs, dashboard_address='localhost:8787', memory_limit="{}GB".format(2*args.n_jobs), processes=True, threads_per_worker=1)
        localCluster = LocalCluster(n_workers=args.n_jobs, dashboard_address='localhost:8787', memory_limit=None, processes=True, threads_per_worker=1)
        #localCluster = LocalCluster(n_workers=args.n_jobs, dashboard_address='localhost:8787', processes=True, threads_per_worker=1)
        client = Client(localCluster)

        print("Running a local cluster with {} processes.".format(args.n_jobs))
        print("Dask dashboard at: {}".format(client.dashboard_link))
        # args.local_cluster = localCluster
    else:
        print("Running computations synchronously.")

    jobs = []
    map_count = 0
    reduction_count = 0
    map_count = 0

    # Rename compute functions to get better reporting on the dask dashboard
    def _rename_op(op, func):
        _op = op
        _op.__name__ = func
        return _op

    # visualize(jobs, filename="out.svg", optimize_graph=True)

    print("", flush=True)
    if args.scratch:
        print("Moving data into scratch folder.", flush=True)
        for ztfname in ztfnames:
            for filtercode in filtercodes:
                band_path = args.wd.joinpath("{}/{}".format(ztfname, filtercode))
                if band_path.exists():
                    scratch_band_path = args.scratch.joinpath("{}/{}".format(ztfname, filtercode))
                    print("Moving {}-{} into {}".format(ztfname, filtercode, scratch_band_path), flush=True)
                    shutil.rmtree(scratch_band_path, ignore_errors=True)
                    quadrant_folder = args.wd.joinpath("{}/{}".format(ztfname, filtercode))
                    if args.from_scratch:
                        def _from_scratch_ignore(current_folder, files):
                            to_copy = [".dbstuff", "elixir.fits", "dead.fits.gz"]
                            to_ignore = [str(f) for f in map(lambda x: pathlib.Path(x), files) if (str(f.name) not in to_copy) and not (pathlib.Path(current_folder).joinpath(f).is_dir() and str(f)[:4] == "ztf_")]
                            return to_ignore
                        shutil.copytree(band_path, scratch_band_path, symlinks=True, dirs_exist_ok=True, ignore=_from_scratch_ignore)
                    else:
                        shutil.copytree(args.wd.joinpath("{}/{}".format(ztfname, filtercode)), scratch_band_path, symlinks=True)

    if args.compress:
        for ztfname in ztfnames:
            for filtercode in filtercodes:
                if args.scratch:
                    cd = args.scratch
                else:
                    cd = args.wd
                if not cd.joinpath("{}/{}/lightcurve.tar".format(ztfname, filtercode)).exists():
                    continue

                print("Uncompressing {}-{} into {}... ".format(ztfname, filtercode, cd), end="", flush=True)
                lightcurve = Lightcurve(ztfname, filtercode, cd)
                lightcurve.uncompress()
                print("Done")

    for ztfname in ztfnames:
        for filtercode in filtercodes:
            print("Building job list for {}-{}... ".format(ztfname, filtercode), flush=True, end="")

            band_path = args.wd.joinpath("{}/{}".format(ztfname, filtercode))

            if not band_path.exists():
                print("No quadrant found.")
                continue

            quadrants = quadrants_from_band_path(band_path, logger, paths=False, ignore_noprocess=True)
            print("{} quadrants found.".format(len(quadrants)))

            sn_jobs = []
            map_jobs = []
            reduce_job = None
            sn_job = None
            last_job = None
            for func in funcs:
                wd = args.wd
                if args.scratch and func != 'clean':
                    wd = args.scratch

                print("Pipeline function \"{}\". ".format(func), flush=True, end="")
                map_run = False
                if 'map' in poloka_func[func].keys() and not args.no_map:
                    map_run = True
                    map_count += len(quadrants)
                    print("(building map jobs)", flush=True, end="")
                    map_jobs = [delayed(_rename_op(map_op, func))(quadrant, wd, ztfname, filtercode, func, args) for quadrant in quadrants]

                    if last_job is not None:
                        print("(checkpoint)", flush=True, end="")
                        map_job = checkpoint(map_jobs)
                        print("(binding)", flush=True, end="")
                        map_job = bind(map_job, last_job)
                    else:
                        map_job = map_jobs

                    print("{} map operations. ".format(len(quadrants)), end="", flush=True)
                else:
                    map_job = None

                if ('reduce' in poloka_func[func].keys() or args.dump_timings) and not args.no_reduce:
                    print("(building reduce job)", flush=True, end="")
                    reduce_job = delayed(_rename_op(reduce_op, func + "_reduce"))(wd, ztfname, filtercode, func, True, args)
                    print("(binding)", flush=True, end="")
                    if map_job is not None:
                        last_job = bind(reduce_job, map_job)
                    else:
                        last_job = bind(reduce_job, last_job)

                    reduction_count += 1
                    print("Reduction operation.", end="", flush=True)
                elif map_run:
                    last_job = checkpoint(map_job)

                print("")

            jobs.append(last_job)

    print("")
    print("Running. ", end="", flush=True)

    if map_count > 0:
        print("Processing {} mappings. ".format(map_count), end="", flush=True)

    if reduction_count > 0:
        print("Processing {} reductions.".format(reduction_count), end="", flush=True)

    print("", flush=True)

    start_time = time.perf_counter()
    if args.synchronous_compute:
        compute(jobs, scheduler="sync")
    else:
        fjobs = client.compute(jobs)
        wait(fjobs)

    end_time = time.perf_counter()

    print("Done. Elapsed time={}".format(end_time - start_time))
    if len(ztfnames) == 1 and len(filtercodes) == 1:
        dump_timings(start_time, end_time, args.wd.joinpath("{}/{}/timings_total".format(ztfnames[0], filtercodes[0])))

    if not args.synchronous_compute:
        client.close(30)
        client.shutdown()

    if args.scratch:
        print("Moving data back from scratch folder into working directory.")
        print("Scratch folder: {}".format(args.scratch))
        print("Working directory: {}".format(args.wd))

        to_ignore = ["elixir.fits", "dead.fits.gz"]
        if args.discard_calibrated:
            to_ignore.extend(["calibrated.fits", "weight.fz"])

        print("Ignoring files {}".format(to_ignore))
        shutil.copytree(args.scratch, args.wd, dirs_exist_ok=True, ignore=shutil.ignore_patterns(*to_ignore))
        shutil.rmtree(args.scratch)
        print("Done")
